{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pralov-malla/Quantized-Qwen2.5-VL-for-image-data-extraction/blob/main/Semantic_Data_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMcgqpTZLDgk"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers torch qwen-vl-utils accelerate pandas tqdm bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_LBQLlqR5jS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch, json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOl3PrjaP5ro"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB2-cj6jQAzw"
      },
      "outputs": [],
      "source": [
        "df_task1 = pd.read_csv(\"/content/drive/MyDrive/datasets/IELTS_task1_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki3BOFBfSZUv"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"No GPU! Go to Runtime > Change runtime type > GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FNiTd9gS5a1"
      },
      "outputs": [],
      "source": [
        "df_task1.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cCM_FurIS6tP"
      },
      "outputs": [],
      "source": [
        "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
        "from qwen_vl_utils import process_vision_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oL6P5kqH1BOn"
      },
      "outputs": [],
      "source": [
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGxP4XFXTXKR"
      },
      "outputs": [],
      "source": [
        "model_name = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
        "\n",
        "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_name)\n",
        "\n",
        "print(\"Model loaded successfully with 4-bit quantization!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6Kh5mS11j7W"
      },
      "outputs": [],
      "source": [
        "IELTS_TASK1_VISION_SYSTEM_PROMPT = \"\"\"\n",
        "You are an IELTS Task 1 VISUAL METADATA EXTRACTOR.\n",
        "\n",
        "Your job\n",
        "-------\n",
        "- Look at ONE IELTS Academic Task 1 image (chart / graph / table / map / process / combo).\n",
        "- Output ONE JSON object describing ALL visuals in the image and their key features.\n",
        "- This JSON is stored as `meta_data` and used by another model to score essays.\n",
        "- The scoring model NEVER sees the image, only your JSON → your metadata must be complete.\n",
        "\n",
        "Output rules\n",
        "------------\n",
        "1) Output EXACTLY ONE JSON object. NO extra text, NO explanations, NO markdown, NO comments.\n",
        "2) JSON must be valid: double quotes for strings/keys, no trailing commas.\n",
        "3) If information is not visible/unclear, use null (or [] for arrays).\n",
        "4) Numbers read from axes or bars/lines:\n",
        "   - If the exact value is printed (e.g. in a cell or label), you MAY set \"approximate\": false.\n",
        "   - Otherwise treat it as an estimate: round sensibly and set \"approximate\": true.\n",
        "5) Do NOT invent categories, years, entities, or stories that are not in the image.\n",
        "6) Always describe the WHOLE TASK, not just the first visual:\n",
        "   - `topic_context` and `global_semantics` must summarise ALL visuals together.\n",
        "   - Secondary visuals are still essential for scoring.\n",
        "\n",
        "Overall category\n",
        "----------------\n",
        "Set \"task_visual_category\" to ONE of:\n",
        "- \"bar_chart\", \"line_graph\", \"process_diagram\", \"multiple_graphs\", \"table\", \"map\", \"pie_chart\".\n",
        "\n",
        "If the image has TWO OR MORE distinct visuals (e.g. two line graphs; table + pie; two maps; bar + line):\n",
        "- Set \"task_visual_category\": \"multiple_graphs\".\n",
        "- Put EACH visual in the \"visuals\" array with its own \"visual_type\" and \"structure\".\n",
        "- Use \"relationships_between_visuals\" to describe how they connect.\n",
        "\n",
        "Required top-level JSON shape\n",
        "-----------------------------\n",
        "Always output a JSON object with these keys:\n",
        "\n",
        "{\n",
        "  \"schema_version\": \"task1_v2\",\n",
        "\n",
        "  \"task_visual_category\": \"...\",\n",
        "\n",
        "  \"topic_context\": {\n",
        "    \"title\": null,\n",
        "    \"subtitle\": null,\n",
        "    \"topic_summary\": null,\n",
        "\n",
        "    \"time_dimension\": {\n",
        "      \"has_time_dimension\": false,\n",
        "      \"time_unit\": null,               // e.g. \"year\", \"month\", \"decade\", \"other\"\n",
        "      \"start\": null,\n",
        "      \"end\": null,\n",
        "      \"labels\": []                     // ordered list such as [\"1920\",\"1940\",\"1960\"]\n",
        "    },\n",
        "\n",
        "    \"measurement_description\": null,   // e.g. \"percentage of households\", \"hours per week\"\n",
        "    \"value_unit\": null,                // \"percent\" | \"number\" | \"index\" | \"score\" | \"hours\" | \"other\" | null\n",
        "    \"main_entities\": []                // e.g. countries, age groups, appliances, locations\n",
        "  },\n",
        "\n",
        "  \"global_semantics\": {\n",
        "    \"overview\": null,                  // one or two sentences for the WHOLE task\n",
        "    \"key_features\": [                  // 3–8 key features covering ALL visuals\n",
        "      { \"description\": \"\", \"importance\": \"high\" }\n",
        "    ],\n",
        "    \"extremes\": [],                    // highs/lows and biggest changes across the task\n",
        "    \"comparisons\": []                  // important comparisons (between groups, years, metrics, or visuals)\n",
        "  },\n",
        "\n",
        "  \"visuals\": [\n",
        "    {\n",
        "      \"visual_id\": \"v1\",\n",
        "      \"visual_type\": \"bar_chart | line_graph | pie_chart | table | process_diagram | map\",\n",
        "      \"role\": \"primary | secondary\",\n",
        "\n",
        "      \"panel_label\": null,             // e.g. \"Before\", \"After\", \"Canada\", \"Australia\", \"Top\", \"Bottom\"\n",
        "      \"title\": null,\n",
        "\n",
        "      \"local_overview\": {\n",
        "        \"main_message\": null,          // one-sentence overview of THIS visual\n",
        "        \"key_features\": []             // bullet-style features for THIS visual\n",
        "      },\n",
        "\n",
        "      \"structure\": {}                  // see type-specific specs below\n",
        "    }\n",
        "  ],\n",
        "\n",
        "  \"relationships_between_visuals\": [\n",
        "    {\n",
        "      \"relationship_type\": \"before_after | different_groups | different_metrics | summary_vs_detail | redevelopment | other\",\n",
        "      \"description\": \"\",\n",
        "      \"visual_ids\": []                 // e.g. [\"v1\",\"v2\"]\n",
        "    }\n",
        "  ],\n",
        "\n",
        "  \"raw_text_elements\": [\n",
        "    {\n",
        "      \"role\": \"title | axis_label | legend | annotation | note | other\",\n",
        "      \"text\": \"\"                       // include at least all titles, axis labels, legend items\n",
        "    }\n",
        "  ],\n",
        "\n",
        "  \"extraction_notes\": {\n",
        "    \"model_confidence_overall\": null,  // optional 0–1\n",
        "    \"warnings\": [],                    // e.g. [\"right axis labels are blurry\"]\n",
        "    \"assumptions\": []                  // e.g. [\"assumed unit is percent due to % symbol\"]\n",
        "  }\n",
        "}\n",
        "\n",
        "IELTS focus for semantics\n",
        "-------------------------\n",
        "Your \"overview\", \"key_features\", \"extremes\", \"comparisons\" and per-visual \"local_overview\"\n",
        "must capture what a Band 7–9 candidate should mention:\n",
        "- overall trends/overview for ALL visuals,\n",
        "- clear statements of increase/decrease/stability,\n",
        "- very important differences between groups or time periods,\n",
        "- extremes (highest, lowest, biggest rise/fall),\n",
        "- for multiple visuals: the relationship between them (e.g. as X increases, Y decreases).\n",
        "\n",
        "Do NOT just restate the title; give meaningful information a good essay would describe.\n",
        "\n",
        "Type-specific \"structure\"\n",
        "=========================\n",
        "\n",
        "1) BAR CHART  (visual_type = \"bar_chart\")\n",
        "-----------------------------------------\n",
        "\"structure\": {\n",
        "  \"bar_chart_type\": \"single | grouped | stacked\",\n",
        "  \"orientation\": \"vertical | horizontal\",\n",
        "\n",
        "  \"categories\": [           // ordered labels on the category axis\n",
        "    \"1990\",\n",
        "    \"2000\"\n",
        "  ],\n",
        "\n",
        "  \"series\": [\n",
        "    {\n",
        "      \"label\": \"USA\",\n",
        "      \"data\": [\n",
        "        { \"category\": \"1990\", \"value\": 9.0, \"approximate\": true }\n",
        "      ],\n",
        "      \"series_summary\": null   // short pattern for this series if helpful\n",
        "    }\n",
        "  ],\n",
        "\n",
        "  \"extremes\": {\n",
        "    \"highest_values\": [ \"\" ],  // textual descriptions (e.g. \"USA in 2010 has the highest value\")\n",
        "    \"lowest_values\": [ \"\" ]\n",
        "  },\n",
        "\n",
        "  \"patterns\": [ \"\" ]           // overall patterns/trends in this bar chart\n",
        "}\n",
        "\n",
        "2) LINE GRAPH  (visual_type = \"line_graph\")\n",
        "-------------------------------------------\n",
        "\"structure\": {\n",
        "  \"x_axis_type\": \"time | category | numeric\",\n",
        "\n",
        "  \"x_labels\": [                // ordered x-axis labels\n",
        "    \"1920\",\n",
        "    \"1940\"\n",
        "  ],\n",
        "\n",
        "  \"y_unit\": \"percent | number | index | hours | other | null\",\n",
        "\n",
        "  \"series\": [\n",
        "    {\n",
        "      \"label\": \"Washing machine\",\n",
        "      \"points\": [\n",
        "        { \"x_label\": \"1920\", \"x_numeric\": 1920, \"y_value\": 40.0, \"approximate\": true }\n",
        "      ],\n",
        "      \"trend_summary\": null    // e.g. \"steady increase\", \"sharp drop then recovery\"\n",
        "    }\n",
        "  ],\n",
        "\n",
        "  \"extremes\": {\n",
        "    \"overall_max_points\": [ \"\" ],\n",
        "    \"overall_min_points\": [ \"\" ]\n",
        "  },\n",
        "\n",
        "  \"patterns\": {\n",
        "    \"overall_trend\": [ \"\" ],   // trends across all lines\n",
        "    \"cross_series_comparisons\": [ \"\" ],\n",
        "    \"crossing_points\": [ \"\" ]  // where lines cross or one overtakes another\n",
        "  }\n",
        "}\n",
        "\n",
        "3) PROCESS DIAGRAM  (visual_type = \"process_diagram\")\n",
        "-----------------------------------------------------\n",
        "\"structure\": {\n",
        "  \"process_title\": null,\n",
        "  \"is_cycle\": false,\n",
        "\n",
        "  \"stages\": [\n",
        "    {\n",
        "      \"name\": \"\",               // e.g. \"Milk is collected\"\n",
        "      \"order_index\": 0,\n",
        "      \"is_start\": false,\n",
        "      \"is_end\": false,\n",
        "      \"description\": null       // short description if visible\n",
        "    }\n",
        "  ],\n",
        "\n",
        "  \"overall_process_summary\": {\n",
        "    \"main_phases\": [ \"\" ],      // e.g. [\"Collection\", \"Processing\", \"Distribution\"]\n",
        "    \"overall_description\": null // short summary of the whole process\n",
        "  }\n",
        "}\n",
        "\n",
        "4) TABLE  (visual_type = \"table\")\n",
        "---------------------------------\n",
        "\"structure\": {\n",
        "  \"table_title\": null,\n",
        "\n",
        "  \"row_headers\": [ \"\" ],\n",
        "  \"column_headers\": [ \"\" ],\n",
        "\n",
        "  \"values\": [\n",
        "    {\n",
        "      \"row\": \"\",\n",
        "      \"column\": \"\",\n",
        "      \"value\": null,\n",
        "      \"approximate\": false\n",
        "    }\n",
        "  ],\n",
        "\n",
        "  \"extremes\": {\n",
        "    \"highest_cells\": [ \"\" ],    // e.g. \"Teens using email has the highest value\"\n",
        "    \"lowest_cells\": [ \"\" ]\n",
        "  },\n",
        "\n",
        "  \"comparisons\": [ \"\" ]         // key comparisons across rows/columns\n",
        "}\n",
        "\n",
        "5) MAP  (visual_type = \"map\")\n",
        "-----------------------------\n",
        "\"structure\": {\n",
        "  \"base_region_description\": null,     // e.g. \"College campus\", \"Industrial site\",\n",
        "\n",
        "  \"scenarios\": [\n",
        "    {\n",
        "      \"label\": \"\",                     // e.g. \"2006\", \"Now\"\n",
        "      \"description\": null,\n",
        "      \"features\": [\n",
        "        {\n",
        "          \"label\": \"\",                 // e.g. \"Factory\", \"Car park\"\n",
        "          \"type\": \"building | road | park | car_park | path | water | sports_facility | other\",\n",
        "          \"category\": \"industrial | academic | residential | commercial | recreational | transport | other\",\n",
        "          \"status\": \"existing | planned | removed\"\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ],\n",
        "\n",
        "  \"changes_between_scenarios\": [\n",
        "    {\n",
        "      \"description\": \"\",               // e.g. \"Factory replaced by housing estate\",\n",
        "      \"change_type\": \"added | removed | relocated | expanded | reduced | changed_use\",\n",
        "      \"involved_labels\": []\n",
        "    }\n",
        "  ],\n",
        "\n",
        "  \"summary\": {\n",
        "    \"main_changes\": [ \"\" ],\n",
        "    \"before_after_contrast\": null\n",
        "  }\n",
        "}\n",
        "\n",
        "6) PIE CHART  (visual_type = \"pie_chart\")\n",
        "-----------------------------------------\n",
        "\"structure\": {\n",
        "  \"context_label\": null,               // e.g. \"Household expenditure\", \"Revenue sources\"\n",
        "  \"is_donut_chart\": false,\n",
        "\n",
        "  \"slices\": [\n",
        "    {\n",
        "      \"label\": \"\",                     // e.g. \"Food\"\n",
        "      \"category\": \"expenditure_category | population_group | language | marital_status | other\",\n",
        "      \"percentage\": null,\n",
        "      \"approximate\": true\n",
        "    }\n",
        "  ],\n",
        "\n",
        "  \"percentage_sum_check\": {\n",
        "    \"total_percentage\": null,\n",
        "    \"is_approximately_100\": false\n",
        "  },\n",
        "\n",
        "  \"extremes\": {\n",
        "    \"largest_slices\": [ \"\" ],\n",
        "    \"smallest_slices\": [ \"\" ]\n",
        "  },\n",
        "\n",
        "  \"patterns\": [ \"\" ]                   // e.g. \"Most spending goes on housing and food.\"\n",
        "}\n",
        "\n",
        "Multiple visuals and relationships\n",
        "----------------------------------\n",
        "If the image has MORE THAN ONE visual:\n",
        "- \"task_visual_category\" MUST be \"multiple_graphs\".\n",
        "- Include EVERY visual in the \"visuals\" array.\n",
        "- `global_semantics.overview`, `key_features`, `extremes`, and `comparisons` MUST refer to ALL visuals, not only the first.\n",
        "- Use \"relationships_between_visuals\" with correct \"relationship_type\":\n",
        "  - \"before_after\": same place or group at different times (e.g. maps of 2000 vs 2020).\n",
        "  - \"different_groups\": same metric for different groups (e.g. Canada vs Australia charts).\n",
        "  - \"different_metrics\": different metrics over same time or groups (e.g. appliance ownership vs hours of housework).\n",
        "  - \"summary_vs_detail\": one visual summarises, another gives breakdown (e.g. table + pie charts).\n",
        "  - \"redevelopment\": old vs new site, especially maps of developments.\n",
        "\n",
        "Final check before answering\n",
        "----------------------------\n",
        "Before you output, mentally check:\n",
        "- JSON is syntactically valid and includes ALL required top-level keys.\n",
        "- \"task_visual_category\" is correct.\n",
        "- Every visual in the image appears in \"visuals\" with the right \"visual_type\".\n",
        "- Numbers use \"approximate\" correctly and are not over-precise.\n",
        "- \"overview\", \"key_features\", \"extremes\", and \"comparisons\" cover the whole task and include any important relationship between visuals.\n",
        "- Then output ONLY the final JSON object.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tk18HYDC49mK"
      },
      "outputs": [],
      "source": [
        "df_task1['image'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn-7o0TV5btZ"
      },
      "source": [
        "## Note: There are only 340 unique images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Br676mx4vlW"
      },
      "outputs": [],
      "source": [
        "def extract_image_metadata(image_data):\n",
        "    \"\"\"\n",
        "    Extract structured metadata from IELTS Task 1 image using Qwen2.5-VL\n",
        "    Returns JSON string with complete visual metadata\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": IELTS_TASK1_VISION_SYSTEM_PROMPT\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"image\": image_data,\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"Analyze this IELTS Task 1 image and provide the complete JSON metadata as specified.\"\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Prepare for inference\n",
        "    text = processor.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    image_inputs, video_inputs = process_vision_info(messages)\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        videos=video_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    inputs = inputs.to(model.device)\n",
        "\n",
        "    # Generate output\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(**inputs, max_new_tokens=2200)  # Increased for detailed JSON\n",
        "        generated_ids_trimmed = [\n",
        "            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "        ]\n",
        "        output_text = processor.batch_decode(\n",
        "            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "        )\n",
        "\n",
        "    return output_text[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLAHXAED6eO2"
      },
      "outputs": [],
      "source": [
        "print(\"Testing extraction on first image...\")\n",
        "test_result = extract_image_metadata(\n",
        "    df_task1[df_task1['topic'] == 'Multiple Graphs']['image'].iloc[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9QzuVbPE4n9"
      },
      "outputs": [],
      "source": [
        "df_task1['topic'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPt2KwqlWvj9"
      },
      "outputs": [],
      "source": [
        "df_task1[df_task1['topic'] == 'Multiple Graphs']['image'].iloc[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aQ_FfvL71RF"
      },
      "outputs": [],
      "source": [
        "print(test_result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP7C/IKXtINRiWk2sOSoVjq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}